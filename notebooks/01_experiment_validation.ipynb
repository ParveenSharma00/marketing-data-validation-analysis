{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 1.1 focused on understanding the dataset structure and validating experiment-related fields. We confirmed that each row represents a user-level observation, verified the presence of only two test groups (Ad vs PSA), ensured conversion was binary, and standardized data types for accurate downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Update path if needed\n",
    "df = pd.read_csv(\"/Users/parveenkumarsharma/Documents/Ecom_project/A_B_testing/marketing_AB.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully ‚úÖ\n",
      "\n",
      "================ DATASET SHAPE ================\n",
      "Number of rows (observations): 588101\n",
      "Number of columns (features): 7\n",
      "\n",
      "================ COLUMN NAMES ================\n",
      "['Unnamed: 0', 'user id', 'test group', 'converted', 'total ads', 'most ads day', 'most ads hour']\n",
      "\n",
      "================ FIRST 5 ROWS ================\n",
      "   Unnamed: 0  user id test group  converted  total ads most ads day  \\\n",
      "0           0  1069124         ad      False        130       Monday   \n",
      "1           1  1119715         ad      False         93      Tuesday   \n",
      "2           2  1144181         ad      False         21      Tuesday   \n",
      "3           3  1435133         ad      False        355      Tuesday   \n",
      "4           4  1015700         ad      False        276       Friday   \n",
      "\n",
      "   most ads hour  \n",
      "0             20  \n",
      "1             22  \n",
      "2             18  \n",
      "3             10  \n",
      "4             14  \n",
      "\n",
      "================ DATA TYPES & INFO ================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588101 entries, 0 to 588100\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Unnamed: 0     588101 non-null  int64 \n",
      " 1   user id        588101 non-null  int64 \n",
      " 2   test group     588101 non-null  object\n",
      " 3   converted      588101 non-null  bool  \n",
      " 4   total ads      588101 non-null  int64 \n",
      " 5   most ads day   588101 non-null  object\n",
      " 6   most ads hour  588101 non-null  int64 \n",
      "dtypes: bool(1), int64(4), object(2)\n",
      "memory usage: 27.5+ MB\n",
      "None\n",
      "\n",
      "================ UNIQUE VALUES CHECK ================\n",
      "\n",
      "Test Group Unique Values:\n",
      "['ad' 'psa']\n",
      "\n",
      "Converted Unique Values:\n",
      "[False  True]\n",
      "\n",
      "================ NUMERICAL SUMMARY ================\n",
      "       Unnamed: 0      user id   total ads  most ads hour\n",
      "count 588101.0000  588101.0000 588101.0000    588101.0000\n",
      "mean  294050.0000 1310692.2158     24.8209        14.4691\n",
      "std   169770.2797  202225.9831     43.7152         4.8346\n",
      "min        0.0000  900000.0000      1.0000         0.0000\n",
      "25%   147025.0000 1143190.0000      4.0000        11.0000\n",
      "50%   294050.0000 1313725.0000     13.0000        14.0000\n",
      "75%   441075.0000 1484088.0000     27.0000        18.0000\n",
      "max   588100.0000 1654483.0000   2065.0000        23.0000\n",
      "\n",
      "================ QUICK SANITY CHECKS ================\n",
      "Users with negative ad exposure: 0\n",
      "Users above 99th percentile ad exposure: 5810\n",
      "\n",
      "Test Group Distribution:\n",
      "test group\n",
      "ad     564577\n",
      "psa     23524\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Group Percentage Distribution:\n",
      "test group\n",
      "ad    96.0000\n",
      "psa    4.0000\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Columns Renamed for Clean Analysis ‚úÖ\n",
      "\n",
      "Data Types After Conversion:\n",
      "index               int64\n",
      "user_id             int64\n",
      "test_group       category\n",
      "converted           int64\n",
      "total_ads           int64\n",
      "most_ads_day       object\n",
      "most_ads_hour       int64\n",
      "dtype: object\n",
      "\n",
      "================ FINAL STRUCTURE CHECK ================\n",
      "   index  user_id test_group  converted  total_ads most_ads_day  most_ads_hour\n",
      "0      0  1069124         ad          0        130       Monday             20\n",
      "1      1  1119715         ad          0         93      Tuesday             22\n",
      "2      2  1144181         ad          0         21      Tuesday             18\n",
      "3      3  1435133         ad          0        355      Tuesday             10\n",
      "4      4  1015700         ad          0        276       Friday             14\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588101 entries, 0 to 588100\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   index          588101 non-null  int64   \n",
      " 1   user_id        588101 non-null  int64   \n",
      " 2   test_group     588101 non-null  category\n",
      " 3   converted      588101 non-null  int64   \n",
      " 4   total_ads      588101 non-null  int64   \n",
      " 5   most_ads_day   588101 non-null  object  \n",
      " 6   most_ads_hour  588101 non-null  int64   \n",
      "dtypes: category(1), int64(5), object(1)\n",
      "memory usage: 27.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# STEP 1.1 ‚Äî DATA STRUCTURE UNDERSTANDING\n",
    "# Objective:\n",
    "#   - Understand dataset shape\n",
    "#   - Validate schema & data types\n",
    "#   - Confirm experiment structure\n",
    "#   - Ensure dataset is ready for validation checks\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Import Required Libraries\n",
    "# -------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Optional display settings for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Load Dataset\n",
    "# -------------------------------\n",
    "\n",
    "print(\"Dataset Loaded Successfully ‚úÖ\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Basic Dataset Overview\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\n================ DATASET SHAPE ================\")\n",
    "print(f\"Number of rows (observations): {df.shape[0]}\")\n",
    "print(f\"Number of columns (features): {df.shape[1]}\")\n",
    "\n",
    "\n",
    "print(\"\\n================ COLUMN NAMES ================\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "print(\"\\n================ FIRST 5 ROWS ================\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Data Types & Non-Null Count (Schema Validation)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ DATA TYPES & INFO ================\")\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5Ô∏è‚É£ Unique Values in Key Experiment Columns\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ UNIQUE VALUES CHECK ================\")\n",
    "\n",
    "print(\"\\nTest Group Unique Values:\")\n",
    "print(df['test group'].unique())\n",
    "\n",
    "print(\"\\nConverted Unique Values:\")\n",
    "print(df['converted'].unique())\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6Ô∏è‚É£ Basic Statistical Summary\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ NUMERICAL SUMMARY ================\")\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7Ô∏è‚É£ Quick Logical Sanity Checks\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ QUICK SANITY CHECKS ================\")\n",
    "\n",
    "# Check if any negative ad exposures\n",
    "negative_ads = df[df['total ads'] < 0]\n",
    "print(f\"Users with negative ad exposure: {len(negative_ads)}\")\n",
    "\n",
    "# Check for extremely high ad exposure (potential outliers)\n",
    "high_ads = df[df['total ads'] > df['total ads'].quantile(0.99)]\n",
    "print(f\"Users above 99th percentile ad exposure: {len(high_ads)}\")\n",
    "\n",
    "# Check distribution of test groups\n",
    "print(\"\\nTest Group Distribution:\")\n",
    "print(df['test group'].value_counts())\n",
    "\n",
    "print(\"\\nTest Group Percentage Distribution:\")\n",
    "print(df['test group'].value_counts(normalize=True) * 100)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8Ô∏è‚É£ Rename Columns for Cleaner Analysis (Best Practice)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Rename columns for easier coding\n",
    "df.columns = [\n",
    "    \"index\",\n",
    "    \"user_id\",\n",
    "    \"test_group\",\n",
    "    \"converted\",\n",
    "    \"total_ads\",\n",
    "    \"most_ads_day\",\n",
    "    \"most_ads_hour\"\n",
    "]\n",
    "\n",
    "print(\"\\nColumns Renamed for Clean Analysis ‚úÖ\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 9Ô∏è‚É£ Convert Data Types Properly\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Convert test_group to categorical\n",
    "df[\"test_group\"] = df[\"test_group\"].astype(\"category\")\n",
    "\n",
    "# Convert converted to integer (0/1)\n",
    "df[\"converted\"] = df[\"converted\"].astype(int)\n",
    "\n",
    "print(\"\\nData Types After Conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# üîü Final Structure Confirmation\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ FINAL STRUCTURE CHECK ================\")\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
